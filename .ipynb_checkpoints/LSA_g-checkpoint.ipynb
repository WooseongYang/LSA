{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import joblib\n",
    "import pickle\n",
    "import pyLDAvis.gensim\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Movies_pre = r'./data/preprocessed/Movies_3.pickle'\n",
    "path_Music_pre = r'./data/preprocessed/Music_3.pickle'\n",
    "path_Appliances_pre = r'./data/preprocessed/Appliances_3.pickle'\n",
    "path_Fashion_pre = r'./data/preprocessed/Fashion_3.pickle'\n",
    "path_Beauty_pre  = r'./data/preprocessed/Beauty_3.pickle'\n",
    "path_Books_pre  = r'./data/preprocessed/Books_3.pickle'\n",
    "path_Food_pre  = r'./data/preprocessed/Food_3.pickle'\n",
    "path_Instruments_pre  = r'./data/preprocessed/Instruments_3.pickle'\n",
    "path_Games_pre  = r'./data/preprocessed/Games_3.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_Movies_pre,'rb') as f:\n",
    "    Movies_pre = pickle.load(f)\n",
    "Movies_pre = Movies_pre['clean_doc']\n",
    "with open(path_Music_pre,'rb') as f:\n",
    "    Music_pre = pickle.load(f)\n",
    "Music_pre = Music_pre['clean_doc']\n",
    "with open(path_Appliances_pre,'rb') as f:\n",
    "    Appliances_pre = pickle.load(f)\n",
    "Appliances_pre = Appliances_pre['clean_doc']\n",
    "with open(path_Fashion_pre,'rb') as f:\n",
    "    Fashion_pre = pickle.load(f)\n",
    "Fashion_pre = Fashion_pre['clean_doc']\n",
    "with open(path_Beauty_pre,'rb') as f:\n",
    "    Beauty_pre = pickle.load(f)\n",
    "Beauty_pre = Beauty_pre['clean_doc']\n",
    "with open(path_Books_pre,'rb') as f:\n",
    "    Books_pre = pickle.load(f)\n",
    "Books_pre = Books_pre['clean_doc']\n",
    "with open(path_Food_pre,'rb') as f:\n",
    "    Food_pre = pickle.load(f)\n",
    "Food_pre = Food_pre['clean_doc']\n",
    "with open(path_Instruments_pre,'rb') as f:\n",
    "    Instruments_pre = pickle.load(f)\n",
    "Instruments_pre = Instruments_pre['clean_doc']\n",
    "with open(path_Games_pre,'rb') as f:\n",
    "    Games_pre = pickle.load(f)\n",
    "Games_pre = Games_pre['clean_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [really, happy, episodes, wish, include, chill...\n",
       "1         [awful, since, husband, lineman, years, movie,...\n",
       "2         [like, story, movie, character, act, also, int...\n",
       "3                                                   [funny]\n",
       "4          [little, disappoint, would, rather, dvds, watch]\n",
       "                                ...                        \n",
       "218717    [wonderful, comedy, remind, fletch, movies, tu...\n",
       "218718    [nostalgic, remembrance, upstairs, downstairs,...\n",
       "218719    [movie, become, martial, artist, show, everyth...\n",
       "218720    [guess, reason, movie, confuse, complex, plot,...\n",
       "218721    [robin, seven, hood, great, story, bing, crosb...\n",
       "Name: clean_doc, Length: 218722, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies_pre[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2303722\n"
     ]
    }
   ],
   "source": [
    "All_pre = list(Movies_pre) + list(Music_pre) + list(Appliances_pre)+ list(Fashion_pre)+ list(Beauty_pre)+ list(Books_pre)+ list(Food_pre)+ list(Instruments_pre)+ list(Games_pre)\n",
    "print(len(All_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_doc = []\n",
    "for i in range(len(All_pre)):\n",
    "    t = ' '.join(All_pre[i])\n",
    "    detokenized_doc.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2303722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'really happy episodes wish include chilly willy little short cartoon original quality around bad price wish spread like disk cause need episode quality streched cause disk still try actually watch dvd player overall pretty satisfy wish everything original good remember show worth really want watch'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(detokenized_doc))\n",
    "detokenized_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "max_features= 1000, # top 1000\n",
    "#max_df = 0.5, \n",
    "#smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(detokenized_doc)\n",
    "X.shape # TF-IDF matrix shape\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "VT = svd_model.fit_transform(X)\n",
    "Sigma = svd_model.explained_variance_ratio_\n",
    "U = svd_model.components_\n",
    "#svd_model.fit(X)\n",
    "#len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 330984)\n",
      "[[ 3.20578833e-06  6.89936362e-07  4.31099029e-07 ...  6.26445397e-09\n",
      "   6.40763845e-09  3.92046615e-09]\n",
      " [-7.49031886e-07 -3.67025036e-07 -2.32680632e-07 ... -1.62876735e-09\n",
      "   1.29999244e-09 -2.54182495e-09]\n",
      " [ 2.18016914e-06 -1.69594089e-07 -1.11740127e-07 ...  2.61568042e-09\n",
      "   1.69838405e-08  1.42361234e-09]\n",
      " ...\n",
      " [ 2.55335562e-07  1.66958201e-08 -8.90457280e-08 ...  1.18472145e-09\n",
      "  -2.51699721e-09 -7.89545173e-10]\n",
      " [ 3.34642516e-07  7.35987375e-08  2.37181194e-08 ...  3.28458608e-09\n",
      "  -3.36997610e-10 -2.17983542e-09]\n",
      " [ 1.76291627e-07 -7.29257185e-09 -2.24504196e-08 ... -1.49008998e-09\n",
      "   1.12486124e-09  5.99743691e-10]]\n"
     ]
    }
   ],
   "source": [
    "US = np.zeros((len(U), len(U[0])))\n",
    "for i in range(len(U)):\n",
    "    for j in range(len(U[i])):\n",
    "        US[i][j] = U[i][j]*Sigma[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(r'./models/term_sim.pickle','wb') as f:\n",
    "#    pickle.dump(US,f)\n",
    "#with open(r'./models/feature_names.pickle','wb') as f:\n",
    "#    pickle.dump(feature_names,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
